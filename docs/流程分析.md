# Xiaozhi 项目对话流程分析

## 1. 应用启动流程

应用启动时会经历以下步骤：
1. 初始化SharedPreferences和StorageUtil
2. 创建OtaBloc并触发OtaInitialEvent检查设备激活状态
3. 创建ChatBloc并触发ChatInitialEvent建立WebSocket连接
4. 初始化音频组件并加载历史消息

## 2. 消息发送流程（按键对话）

用户通过按住主界面的说话按钮发起对话：

1. 用户长按说话按钮触发`ChatStartListenEvent`
2. 检查麦克风权限，如果未授权则请求权限
3. 发送`typeListen`类型的消息到服务器，状态为`stateStart`
4. 开始音频录制并将PCM数据转换为Opus格式
5. 通过WebSocket发送Opus音频数据到服务器
6. 等待服务器响应

## 3. 消息接收流程

1. 服务器处理完用户的语音后，会返回两种类型的数据：
   - 文本消息(`typeSpeechToText`): 包含语音识别结果
   - 音频数据: 包含文本转语音的音频数据

2. 对于文本消息：
   - 解析JSON文本
   - 触发`ChatOnMessageEvent`
   - 保存消息到本地数据库
   - 更新UI显示

3. 对于音频数据：
   - 接收Opus音频数据
   - 将Opus转换为PCM格式
   - 通过音频播放器播放

## 4. 连续通话流程

用户可以通过进入通话页面实现连续对话：

1. 用户进入通话页面触发`ChatStartCallEvent`
2. 设置通话模式标识并触发`ChatStartListenEvent`
3. 开始录音监听
4. 发送语音到服务端并接收回复文本和音频
5. 播放回复音频
6. 服务端通知结束时自动重新开始监听
7. 用户退出通话页面时触发`ChatStopCallEvent`停止通话模式

## 5. 关键技术细节

### 5.1 音频处理流程

- 录制：麦克风输入 → PCM音频数据 → Opus编码 → WebSocket传输
- 播放：WebSocket接收Opus数据 → Opus解码 → PCM音频数据 → 扬声器输出

### 5.2 WebSocket消息类型

- `typeHello`：建立连接时的握手消息
- `typeListen`：开始/停止录音监听
- `typeSpeechToText`：语音转文本结果
- `typeTextToSpeech`：文本转语音相关消息

### 5.3 状态管理

- 使用BLoC模式进行状态管理
- 通过事件驱动的方式触发状态变更
- UI层监听状态变化并作出相应更新

这套对话流程设计使得用户可以通过按键对话和连续通话两种模式与AI助手进行交互，同时支持文本和语音的双向通信。