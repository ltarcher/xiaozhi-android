import 'dart:async';
import 'dart:convert';
import 'dart:typed_data';
import 'dart:typed_data';
import 'dart:math';

import 'package:bloc/bloc.dart';
import 'package:meta/meta.dart';
import 'package:logger/logger.dart';
import 'package:opus_dart/opus_dart.dart';
import 'package:opus_flutter/opus_flutter.dart' as opus_flutter;
import 'package:permission_handler/permission_handler.dart';
import 'package:record/record.dart';
import 'package:taudio/public/fs/flutter_sound.dart';
import 'package:uuid/uuid.dart';
import 'package:web_socket_channel/io.dart';
import 'package:web_socket_channel/web_socket_channel.dart';
import 'package:xiaozhi/common/x_const.dart';
import 'package:xiaozhi/model/storage_message.dart';
import 'package:xiaozhi/model/websocket_message.dart';
import 'package:xiaozhi/util/common_utils.dart';
import 'package:xiaozhi/util/shared_preferences_util.dart';
import 'package:xiaozhi/util/storage_util.dart';
import 'package:xiaozhi/util/audio_processor.dart';

part 'chat_event.dart';
part 'chat_state.dart';

class ChatBloc extends Bloc<ChatEvent, ChatState> {
  late Logger _logger;

  WebSocketChannel? _websocketChannel;

  StreamSubscription? _websocketStreamSubscription;

  AudioRecorder? _audioRecorder;

  FlutterSoundPlayer? _audioPlayer;

  Stream<Uint8List>? _audioRecorderStream;

  StreamSubscription<Uint8List>? _audioRecorderSubscription;

  String? _sessionId;

  int _audioSampleRate = AudioParams.sampleRate16000;

  int _audioChannels = AudioParams.channels1;

  int _audioFrameDuration = AudioParams.frameDuration60;

  final int _messageListPaginatedLimit = 20;

  int _messageListPaginatedOffset = 0;

  bool _isOnCall = false;
  
  // 添加音频处理器
  late AudioProcessor _audioProcessor;
  
  // 添加口型同步值回调
  Function(double)? _onLipSyncUpdate;

  // 设置口型同步回调
  void setLipSyncCallback(Function(double) onLipSyncUpdate) {
    _onLipSyncUpdate = onLipSyncUpdate;
  }
  
  @override
  Future<void> close() {
    if (null != _websocketStreamSubscription) {
      _websocketStreamSubscription!.cancel();
      _websocketStreamSubscription = null;
    }
    if (null != _audioRecorderSubscription) {
      _audioRecorderSubscription!.cancel();
      _audioRecorderSubscription = null;
    }
    return super.close();
  }

  void _initWebsocketListener() {
    _websocketStreamSubscription = _websocketChannel!.stream.listen(
      (data) async {
        try {
          if (data is String) {
            final WebsocketMessage message = WebsocketMessage.fromJson(
              jsonDecode(data),
            );

            if (null != message.sessionId) {
              _sessionId = message.sessionId;
            }
            if (null != message.audioParams) {
              _audioSampleRate = message.audioParams!.sampleRate;
              _audioChannels = message.audioParams!.channels;
              _audioFrameDuration = message.audioParams!.frameDuration;
            }

            if (message.type == WebsocketMessage.typeSpeechToText) {
              if (null != _audioRecorder &&
                  await _audioRecorder!.isRecording()) {
                await _audioRecorder!.stop();
              }

              if (null != message.text) {
                add(
                  ChatOnMessageEvent(
                    message: StorageMessage(
                      id: Uuid().v4(),
                      text: message.text!,
                      sendByMe: true,
                      createdAt: DateTime.now(),
                    ),
                  ),
                );
              }
            } else if (message.type == WebsocketMessage.typeTextToSpeech &&
                message.state == WebsocketMessage.stateSentenceStart &&
                null != message.text) {
              add(
                ChatOnMessageEvent(
                  message: StorageMessage(
                    id: Uuid().v4(),
                    text: message.text!,
                    sendByMe: false,
                    createdAt: DateTime.now(),
                  ),
                ),
              );
            } else if (message.type == WebsocketMessage.typeTextToSpeech &&
                message.state == WebsocketMessage.stateStop &&
                _isOnCall) {
              add(ChatStartListenEvent());
            }
          } else if (data is Uint8List) {
            // 将opus数据转换为PCM数据
            Uint8List? pcmData = await CommonUtils.opusToPcm(
              opusData: data,
              sampleRate: _audioSampleRate,
              channels: _audioChannels,
            );
            
            if (pcmData != null) {
              // 处理音频数据以计算口型同步值
              _processAudioForLipSync(pcmData);
              
              // 播放音频
              if (false == _audioPlayer!.isOpen()) {
                await _audioPlayer!.openPlayer();
              }

              if (_audioPlayer!.isPlaying) {
                _audioPlayer!.uint8ListSink!.add(pcmData);
              } else {
                await _audioPlayer!.startPlayerFromStream(
                  codec: Codec.pcm16,
                  interleaved: false,
                  numChannels: _audioChannels,
                  sampleRate: _audioSampleRate,
                  bufferSize: 1024,
                );
              }
            }
          }
        } catch (e, s) {
          _logger.e('___ERROR Listen $s $e');
        }
      },
      onError: (e) {
        _logger.e('___ERROR Websocket $e');
      },
      onDone: () {
        _logger.i('___INFO Websocket Closed');
        if (null != _websocketStreamSubscription) {
          _websocketStreamSubscription!.cancel();
          _websocketStreamSubscription = null;
        }
      },
    );
  }
  
  // 处理音频数据以计算口型同步值
  void _processAudioForLipSync(Uint8List pcmData) {
    try {
      // 将PCM字节数据转换为双精度浮点数列表
      List<double> audioSamples = _convertPcmToDouble(pcmData);
      
      // 使用音频处理器计算口型同步值
      double lipSyncValue = _audioProcessor.processAudio(audioSamples);
      
      // 通过回调更新口型同步值
      _onLipSyncUpdate?.call(lipSyncValue);
    } catch (e) {
      _logger.e('Error processing audio for lip sync: $e');
    }
  }
  
  // 将PCM字节数据转换为双精度浮点数列表
  List<double> _convertPcmToDouble(Uint8List pcmData) {
    // 假设PCM数据是16位有符号整数
    List<double> samples = [];
    for (int i = 0; i < pcmData.length - 1; i += 2) {
      // 将两个字节组合成一个16位有符号整数
      int sample = (pcmData[i + 1] << 8) | pcmData[i];
      // 转换为有符号整数
      if (sample > 32767) sample -= 65536;
      // 归一化到-1.0到1.0的范围
      samples.add(sample / 32768.0);
    }
    return samples;
  }

  ChatBloc() : super(ChatInitialState()) {
    _logger = Logger();
    _audioProcessor = AudioProcessor();
    
    on<ChatEvent>((event, emit) async {
      if (event is ChatInitialEvent) {
        try {
          _websocketChannel = IOWebSocketChannel.connect(
            Uri.parse(
              (await SharedPreferencesUtil().getWebsocketUrl()) ??
                  XConst.defaultWebsocketUrl,
            ),
            headers: {
              "Protocol-Version": "1",
              "Device-Id": await SharedPreferencesUtil().getMacAddress(),
            },
          );

          _initWebsocketListener();

          _websocketChannel!.sink.add(
            jsonEncode(
              WebsocketMessage(
                type: WebsocketMessage.typeHello,
                transport: WebsocketMessage.transportWebSocket,
                audioParams: AudioParams(
                  sampleRate: _audioSampleRate,
                  channels: _audioChannels,
                  frameDuration: _audioFrameDuration,
                  format: AudioParams.formatOpus,
                ),
              ).toJson(),
            ),
          );

          _audioRecorder = AudioRecorder();

          _audioPlayer = FlutterSoundPlayer();

          initOpus(await opus_flutter.load());

          List<StorageMessage> messageList = await StorageUtil()
              .getPaginatedMessages(
                limit: _messageListPaginatedLimit,
                offset: _messageListPaginatedOffset,
              );

          emit(ChatInitialState(messageList: messageList));
        } catch (e, s) {
          _logger.e('___ERROR ChatInitialEvent $e $s');
        }
      }

      if (event is ChatStartListenEvent) {
        if (!await Permission.microphone.isGranted) {
          if (!event.isRequestMicrophonePermission ||
              !await Permission.microphone.request().isGranted) {
            emit(ChatNoMicrophonePermissionState());
          }
          if (!_isOnCall) {
            return;
          }
        }

        if (null == _websocketStreamSubscription) {
          _initWebsocketListener();
        }

        _websocketChannel!.sink.add(
          jsonEncode(
            WebsocketMessage(
              type: WebsocketMessage.typeListen,
              sessionId: _sessionId,
              state: WebsocketMessage.stateStart,
              mode: WebsocketMessage.modeAuto,
            ).toJson(),
          ),
        );

        _audioRecorderStream = (await _audioRecorder!.startStream(
          RecordConfig(
            encoder: AudioEncoder.pcm16bits,
            echoCancel: true,
            noiseSuppress: true,
            numChannels: _audioChannels,
            sampleRate: _audioSampleRate,
          ),
        ));

        if (null != _audioRecorderSubscription) {
          _audioRecorderSubscription!.cancel();
          _audioRecorderSubscription = null;
        }

        _audioRecorderSubscription = _audioRecorderStream!.listen((data) async {
          if (_websocketChannel != null &&
              data.isNotEmpty &&
              data.length % 2 == 0) {
            Uint8List? opusData = await CommonUtils.pcmToOpus(
              pcmData: data,
              sampleRate: _audioSampleRate,
              frameDuration: _audioFrameDuration,
            );
            if (null != opusData) {
              _websocketChannel!.sink.add(opusData);
            }
          }
        });
      }

      if (event is ChatOnMessageEvent) {
        await StorageUtil().insertMessage(event.message);
        emit(
          ChatInitialState(messageList: [event.message, ...state.messageList]),
        );
      }

      if (event is ChatLoadMoreEvent) {
        _messageListPaginatedOffset += _messageListPaginatedLimit;
        List<StorageMessage> messageList = await StorageUtil()
            .getPaginatedMessages(
              limit: 20,
              offset: _messageListPaginatedOffset,
            );
        emit(
          ChatInitialState(
            messageList: [...state.messageList, ...messageList],
            hasMore: messageList.length == _messageListPaginatedLimit,
          ),
        );
      }

      if (event is ChatStopListenEvent) {
        if (null != _audioRecorder && (await _audioRecorder!.isRecording())) {
          await _audioRecorder!.stop();
        }
      }

      if (event is ChatStartCallEvent) {
        _isOnCall = true;
        add(ChatStartListenEvent());
      }

      if (event is ChatStopCallEvent) {
        _isOnCall = false;
        add(ChatStopListenEvent());
      }
      
      if (event is ChatNavigateToCallEvent) {
        // 处理从唤醒词跳转到通话页面的请求
        _logger.i('Navigating to call page due to wake word');
      }
    });
  }
}